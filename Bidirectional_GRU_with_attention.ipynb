{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bidirectional GRU with attention",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMhfuLVwR83B"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import scipy.io as scio\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "def Mydata(dataset, labels):\n",
        "    y = []\n",
        "    for i in range(len(labels)):\n",
        "        x = (dataset[i], labels[i].item())\n",
        "        y.append(x)\n",
        "    return tuple(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iua1OC46S_2k"
      },
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters\n",
        "\n",
        "sequence_length = 15\n",
        "input_size = 32 #输入特征维度\n",
        "hidden_size = 256 #隐藏层单元数\n",
        "num_layers = 3 #神经网络层数\n",
        "num_classes = 3 #分类数\n",
        "batch_size = 25 \n",
        "num_epochs = 10\n",
        "learning_rate = 0.008\n",
        "embed_dim = input_size\n",
        "num_samples = 1500"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTkA0WawfrvL"
      },
      "source": [
        "数据读取"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7flG6V-R-OM"
      },
      "source": [
        "dataFile = r'/content/test_data.mat'\n",
        "data = scio.loadmat(dataFile)\n",
        "test_data = data['test_data'].astype(np.double)\n",
        "train_data = data['train_data'].astype(np.double)\n",
        "train_data = torch.from_numpy(train_data)\n",
        "test_data = torch.from_numpy(test_data)\n",
        "\n",
        "label2 = data['test_label'].astype(np.long)\n",
        "label1 = data['train_label'].astype(np.long)\n",
        "train_labels = torch.zeros(num_samples)\n",
        "test_labels = torch.zeros(num_samples)\n",
        "for i in range(num_samples):\n",
        "    if label1[0][i] == 1:\n",
        "        train_labels[i] = 0\n",
        "    elif label1[1][i] == 1:\n",
        "        train_labels[i] = 1\n",
        "    else:\n",
        "        train_labels[i] = 2\n",
        "    if label2[0][i] == 1:\n",
        "        test_labels[i] = 0\n",
        "    elif label2[1][i] == 1:\n",
        "        test_labels[i] = 1\n",
        "    else:\n",
        "        test_labels[i] = 2 \n",
        "train_dataset = Mydata(train_data,train_labels)\n",
        "test_dataset = Mydata(test_data,test_labels)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNx9qc8UfiCF"
      },
      "source": [
        "神经网络模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuDXltU-TBZo"
      },
      "source": [
        "# 双向循环神经网络 (many-to-one)\n",
        "# 将接下来创建的变量类型均为Double\n",
        "torch.set_default_tensor_type(torch.DoubleTensor)\n",
        "\n",
        "class BiRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(BiRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.GRU = nn.GRU(input_size,# x的特征维度\n",
        "                            hidden_size,# 隐藏层单元数\n",
        "                            num_layers,# 层数\n",
        "                            batch_first=True,# 第一个维度设为 batch, 即:(batch_size, seq_length, input_size)\n",
        "                            bidirectional=True) # 是否用双向\n",
        "        self.weight_W = nn.Parameter(torch.Tensor(2 * hidden_size, 2 * hidden_size))\n",
        "        self.weight_proj = nn.Parameter(torch.Tensor(2 * hidden_size, 1))\n",
        "        self.fc = nn.Linear(hidden_size * 2, num_classes)  # 2 for bidirection\n",
        "        nn.init.uniform_(self.weight_W, -0.1, 0.1)\n",
        "        nn.init.uniform_(self.weight_proj, -0.1, 0.1)\n",
        "    def forward(self, x):\n",
        "        # x维度为(batch_size, time_step, input_size)\n",
        "        # 隐层初始化\n",
        "        # h0维度为(num_layers*direction_num, batch_size, hidden_size)\n",
        "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(device)  # 2 for bidirection\n",
        "        #input = input.permute(1, 0, 2)\n",
        "        # LSTM前向传播，此时out维度为(batch_size, seq_length, hidden_size*2)\n",
        "        # hn表示最后一个状态，维度与h0一样\n",
        "        out, hn = self.GRU(x, h0)\n",
        "        # attention机制\n",
        "        x = out\n",
        "        u = torch.tanh(torch.matmul(x, self.weight_W))\n",
        "        att = torch.matmul(u, self.weight_proj)\n",
        "        att_score = F.softmax(att, dim=1)\n",
        "        scored_x = x * att_score\n",
        "        # attention结束\n",
        "        # 最后一步的输出,即(batch_size, -1, output_size)\n",
        "        feat = torch.sum(scored_x, dim=1)\n",
        "        #out = self.fc(out[:, -1, :])\n",
        "\n",
        "        return self.fc(feat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OLOztD6fb5X"
      },
      "source": [
        "训练模块"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2RAKH-mTGon"
      },
      "source": [
        "model = BiRNN(input_size, hidden_size, num_layers, num_classes).to(device)\n",
        "model = model.double()\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "# 下面是训练部分\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = Variable(images.view(-1, sequence_length, input_size).to(device))\n",
        "        labels = Variable(labels.to(device))\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        #print(outputs, labels.long())\n",
        "        loss = criterion(outputs, labels.long())\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #if (i + 1) % 15 == 0:\n",
        "        #    print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uzo90VIfTt1"
      },
      "source": [
        "测试模块"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKJvoklXWcWV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7a8944e5-9d77-43a4-fe3e-190960ea74cf"
      },
      "source": [
        "# Test the model\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "  \n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "   \n",
        "    print('Test Accuracy of the model on the 1500 test images: {} %'.format(100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy of the model on the 1500 test images: 98.66666666666667 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}